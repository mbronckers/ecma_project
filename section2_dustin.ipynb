{
 "cells": [
  {
   "source": [
    "# Section 2: Analyzing Causal Forests on Simulated Data similar to GSS data "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from econml.dml import CausalForestDML\n",
    "\n",
    "from copy import deepcopy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def fullDisplay():\n",
    "    pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "\n",
    "def defaultDisplay():\n",
    "    pd.reset_option('^display.', silent=True)"
   ]
  },
  {
   "source": [
    "## Loading data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       year    id  wrkstat      hrs1      hrs2  evwork  occ  prestige  wrkslf  \\\n",
       "0         0     1        7  0.004845  0.005228       1  135  0.005641       2   \n",
       "1         0     2        1  0.005055  0.005228       0  106  0.006538       2   \n",
       "2         0     3        7  0.004845  0.005228       1   99  0.006538       2   \n",
       "3         0     4        3  0.005055  0.005228       0  142  0.004615       2   \n",
       "4         0     5        8  0.005055  0.005228       1  211  0.005171       2   \n",
       "...     ...   ...      ...       ...       ...     ...  ...       ...     ...   \n",
       "36496    15  2040        3  0.005055  0.005228       0  211  0.005171       2   \n",
       "36497    15  2041        3  0.005055  0.005228       0  211  0.005171       2   \n",
       "36498    15  2042        7  0.004845  0.005228       1  211  0.005171       2   \n",
       "36499    15  2043        7  0.005935  0.005228       1  211  0.005171       2   \n",
       "36500    15  2044        7  0.004845  0.005228       1  211  0.005171       2   \n",
       "\n",
       "       wrkgovt  ...  adults_miss  unrelat_miss  earnrs_miss  income_miss  \\\n",
       "0            2  ...            0             0            0            0   \n",
       "1            2  ...            0             1            0            0   \n",
       "2            2  ...            0             1            0            0   \n",
       "3            0  ...            0             0            0            0   \n",
       "4            1  ...            0             0            0            0   \n",
       "...        ...  ...          ...           ...          ...          ...   \n",
       "36496        2  ...            0             0            0            0   \n",
       "36497        2  ...            0             0            0            0   \n",
       "36498        2  ...            0             1            0            0   \n",
       "36499        2  ...            0             1            0            0   \n",
       "36500        2  ...            0             1            0            0   \n",
       "\n",
       "       rincome_miss  income86_miss  partyid_miss  polviews_miss  attblack  \\\n",
       "0                 0              0             0              0  0.005440   \n",
       "1                 1              0             0              0  0.004080   \n",
       "2                 0              0             0              0  0.002040   \n",
       "3                 1              0             0              0  0.004080   \n",
       "4                 0              0             0              0  0.004080   \n",
       "...             ...            ...           ...            ...       ...   \n",
       "36496             1              1             0              0  0.004080   \n",
       "36497             1              1             0              0  0.006120   \n",
       "36498             0              1             0              0  0.004080   \n",
       "36499             1              1             0              0  0.005021   \n",
       "36500             0              1             0              0  0.008160   \n",
       "\n",
       "       attblack_miss  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  \n",
       "...              ...  \n",
       "36496              0  \n",
       "36497              0  \n",
       "36498              0  \n",
       "36499              1  \n",
       "36500              0  \n",
       "\n",
       "[36501 rows x 120 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>id</th>\n      <th>wrkstat</th>\n      <th>hrs1</th>\n      <th>hrs2</th>\n      <th>evwork</th>\n      <th>occ</th>\n      <th>prestige</th>\n      <th>wrkslf</th>\n      <th>wrkgovt</th>\n      <th>...</th>\n      <th>adults_miss</th>\n      <th>unrelat_miss</th>\n      <th>earnrs_miss</th>\n      <th>income_miss</th>\n      <th>rincome_miss</th>\n      <th>income86_miss</th>\n      <th>partyid_miss</th>\n      <th>polviews_miss</th>\n      <th>attblack</th>\n      <th>attblack_miss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0.004845</td>\n      <td>0.005228</td>\n      <td>1</td>\n      <td>135</td>\n      <td>0.005641</td>\n      <td>2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.005440</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0.005055</td>\n      <td>0.005228</td>\n      <td>0</td>\n      <td>106</td>\n      <td>0.006538</td>\n      <td>2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.004080</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>3</td>\n      <td>7</td>\n      <td>0.004845</td>\n      <td>0.005228</td>\n      <td>1</td>\n      <td>99</td>\n      <td>0.006538</td>\n      <td>2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.002040</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>4</td>\n      <td>3</td>\n      <td>0.005055</td>\n      <td>0.005228</td>\n      <td>0</td>\n      <td>142</td>\n      <td>0.004615</td>\n      <td>2</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.004080</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>5</td>\n      <td>8</td>\n      <td>0.005055</td>\n      <td>0.005228</td>\n      <td>1</td>\n      <td>211</td>\n      <td>0.005171</td>\n      <td>2</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.004080</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>36496</th>\n      <td>15</td>\n      <td>2040</td>\n      <td>3</td>\n      <td>0.005055</td>\n      <td>0.005228</td>\n      <td>0</td>\n      <td>211</td>\n      <td>0.005171</td>\n      <td>2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.004080</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>36497</th>\n      <td>15</td>\n      <td>2041</td>\n      <td>3</td>\n      <td>0.005055</td>\n      <td>0.005228</td>\n      <td>0</td>\n      <td>211</td>\n      <td>0.005171</td>\n      <td>2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.006120</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>36498</th>\n      <td>15</td>\n      <td>2042</td>\n      <td>7</td>\n      <td>0.004845</td>\n      <td>0.005228</td>\n      <td>1</td>\n      <td>211</td>\n      <td>0.005171</td>\n      <td>2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.004080</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>36499</th>\n      <td>15</td>\n      <td>2043</td>\n      <td>7</td>\n      <td>0.005935</td>\n      <td>0.005228</td>\n      <td>1</td>\n      <td>211</td>\n      <td>0.005171</td>\n      <td>2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.005021</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>36500</th>\n      <td>15</td>\n      <td>2044</td>\n      <td>7</td>\n      <td>0.004845</td>\n      <td>0.005228</td>\n      <td>1</td>\n      <td>211</td>\n      <td>0.005171</td>\n      <td>2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.008160</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>36501 rows Ã— 120 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "welfare = pd.read_csv(\"Data/welfare_clean.csv\", low_memory=False)\n",
    "treatments = welfare['w']\n",
    "labels = welfare['y']\n",
    "welfare.drop(columns=['w', 'y'], inplace=True)\n",
    "welfare"
   ]
  },
  {
   "source": [
    "## DGP, Estimation, and Evaluation functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dgp(welfare, effect_type=\"heterogeneous\", effect_homogeneous=10, effect_heterogeneous=2,\n",
    "        treatment_type=\"binary\", treatment_probability=0.5, heterogeneous_select=4, overlap=True,\n",
    "        overlap_percent=0.5, order=3, linearity=\"med\", N=5000):    \n",
    "    \n",
    "    featureNames = list(welfare.columns)\n",
    "\n",
    "    # Define non-confounders\n",
    "    importantFeatureNames = ['wrkstat', 'race', 'year', 'hrs1', 'income', 'occ80', 'id', 'educ'] # top 8 important features based on Shapley visualization from \n",
    "    importantFeatureIndices = []\n",
    "    for name in importantFeatureNames:\n",
    "        importantFeatureIndices.append(featureNames.index(name)) \n",
    "\n",
    "    # Error terms\n",
    "    error = np.random.normal(size=(N,1))\n",
    "\n",
    "    # Data generation\n",
    "    cov = welfare.cov()\n",
    "    means = welfare.mean(axis=0)\n",
    "    X = np.random.multivariate_normal(means.values, cov, size=N, check_valid='warn', tol=1e-8)\n",
    "\n",
    "    # Linearity specification\n",
    "    if linearity != 'full':\n",
    "        select = 0 # select n most important features for interactions and polynomials\n",
    "        poly = PolynomialFeatures(degree=order, interaction_only=False, include_bias=False)\n",
    "\n",
    "        if linearity == \"high\": \n",
    "            select = 2\n",
    "        elif linearity == \"med\": \n",
    "            select = 4\n",
    "        elif linearity == \"low\": \n",
    "            select = 8\n",
    "        else: # if some typo, assume baseline of high\n",
    "            select = 2\n",
    "\n",
    "        poly.fit(X[:, importantFeatureIndices[:select]])\n",
    "        fullData = poly.transform(X[:, importantFeatureIndices[:select]])\n",
    "        fullNames = poly.get_feature_names(input_features=importantFeatureNames[:select])\n",
    "        higherData = fullData[:, -(fullData.shape[1] - select):] # select only higher order\n",
    "        higherNames = fullNames[-(len(fullNames) - select):]\n",
    "\n",
    "        X = np.append(X, higherData, axis=1) \n",
    "        featureNames.extend(list(higherNames))\n",
    "\n",
    "    # Treatment selection\n",
    "    if treatment_type == \"binary\":\n",
    "        # randomly assigned treatments with propensity treatment_probability\n",
    "        treatments = np.random.choice([0, 1], size=N, p=[1 - treatment_probability, treatment_probability]).reshape((-1, 1))\n",
    "        if not overlap:\n",
    "            forced = random.sample(list(np.arange(treatments.shape[0])), int(treatments.shape[0] * overlap_percent))\n",
    "            treatments[forced] = 0\n",
    "        treated = treatments > 0\n",
    "\n",
    "        # generate counterfactual treatment indicator vector\n",
    "        c_treatments = deepcopy(treatments)\n",
    "        c_treatments[treatments == 0] = 1\n",
    "        c_treatments[treatments == 1] = 0\n",
    "    else:\n",
    "        treatments = np.random.uniform(size=(N, 1))\n",
    "        if not overlap:\n",
    "            forced = random.sample(list(np.arange(treatments.shape[0])), int(treatments.shape[0] * overlap_percent))\n",
    "            treatments[forced] = 0\n",
    "        treated = treatments > 0.5\n",
    "\n",
    "        # to-do: counterfactual treatment vector\n",
    "        c_treatments = deepcopy(treatments)\n",
    "        c_treatments[treatments > 0] = 0\n",
    "        c_treatments[treatments == 0] = treatments.mean()\n",
    "\n",
    "    # Treatment effect calculation\n",
    "    if effect_type == \"homogeneous\":\n",
    "\n",
    "        T = treatments*effect_homogeneous\n",
    "        CT = c_treatments*effect_homogeneous\n",
    "\n",
    "    else: \n",
    "        # heterogeneous treatment is effect 1 + effect * (sum of first heterogeneous_select important variables)\n",
    "        heterogeneousIndices = importantFeatureIndices[:heterogeneous_select]\n",
    "\n",
    "        T = 1 + (effect_heterogeneous*(X[:, heterogeneousIndices].sum(axis=1)))*treatments.ravel()\n",
    "        T = T.reshape(-1, 1)\n",
    "        T[~treated] = np.zeros((~treated).sum())\n",
    "        \n",
    "        # counterfactual effect\n",
    "        CT = 1 + (effect_heterogeneous*(X[:, heterogeneousIndices].sum(axis=1)))*c_treatments.ravel()\n",
    "        CT = CT.reshape(-1, 1)\n",
    "        CT[treated] = np.zeros((treated).sum()) # everyone that was treated goes to untreated in counterfactual\n",
    "\n",
    "    # Outcome calculation\n",
    "    betas = np.random.normal(size=X.shape[1]).reshape(-1,1)\n",
    "    y = T + X@betas + error\n",
    "    cy = CT + X@betas + error\n",
    "    \n",
    "    # ATE calculation\n",
    "    empirical_treated = y[treated] - cy[treated] # the treated (in y)\n",
    "    empirical_untreated = cy[~treated] - y[~treated] # the untreated\n",
    "    ate = (empirical_treated.mean() + empirical_untreated.mean())/2\n",
    "    \n",
    "    return y, X, betas, featureNames, treatments, cy, ate\n",
    "\n",
    "def estimate_cf(y, X, treatments, test_size=0.2, criterion='mse', cv=5):\n",
    "    # split data into train and test sets \n",
    "    X_train, X_test, Y_train, Y_test, T_train, T_test = train_test_split(X, y, treatments, test_size=test_size)\n",
    "        \n",
    "    # specify hyperparams of model\n",
    "    est = CausalForestDML(criterion='het', \n",
    "                            n_estimators=1000,       \n",
    "                            max_samples=0.5,\n",
    "                            discrete_treatment=True,\n",
    "                            honest=True,\n",
    "                            inference=True,\n",
    "                            cv=cv,\n",
    "                            )\n",
    "    # fit model\n",
    "    est.fit(Y_train, T_train, X=X_train, W=None)\n",
    "        \n",
    "    return est, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute evaluation stats over K simulations\n",
    "def evalStats(estimators, trueATES, evalSets):\n",
    "    K = len(estimators)\n",
    "    \n",
    "    totalBias = 0\n",
    "    totalRMSE = 0\n",
    "    totalCoverage = 0\n",
    "    totalInterval = 0\n",
    "\n",
    "    for i in range(K):\n",
    "        estimateATE = estimators[i].ate(evalSets[i])\n",
    "        lb, ub = estimators[i].ate_interval(evalSets[i])\n",
    "        \n",
    "        bias = trueATES[i] - estimateATE\n",
    "        totalBias += bias\n",
    "        \n",
    "        rmse = bias**2\n",
    "        totalRMSE += rmse\n",
    "\n",
    "        coverage = 1 if (trueATES[i] >= lb and trueATES[i] <= ub) else 0\n",
    "        totalCoverage += coverage\n",
    "\n",
    "        interval = ub - lb\n",
    "        totalInterval += interval\n",
    "    \n",
    "    return totalBias / K, (totalRMSE / K)**0.5, totalCoverage / K, totalInterval / K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10"
   ]
  },
  {
   "source": [
    "## (1) Sample Size"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-0d45e9a19508>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrueBetas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatureNames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtreatments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdgp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwelfare\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimate_cf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtreatments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mestNs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-06d40b85900f>\u001b[0m in \u001b[0;36mestimate_cf\u001b[0;34m(y, X, treatments, test_size, criterion, cv)\u001b[0m\n\u001b[1;32m    112\u001b[0m                             )\n\u001b[1;32m    113\u001b[0m     \u001b[0;31m# fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m     \u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/econ21340-env/lib/python3.7/site-packages/econml/utilities.py\u001b[0m in \u001b[0;36mm\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrong_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m                 \u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1262\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mto_wrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1263\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1264\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/econ21340-env/lib/python3.7/site-packages/econml/dml/causal_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, Y, T, X, W, sample_weight, groups, cache_values, inference)\u001b[0m\n\u001b[1;32m    744\u001b[0m                            \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m                            \u001b[0mcache_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m                            inference=inference)\n\u001b[0m\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrefit_final\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/econ21340-env/lib/python3.7/site-packages/econml/utilities.py\u001b[0m in \u001b[0;36mm\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrong_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m                 \u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1262\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mto_wrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1263\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1264\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/econ21340-env/lib/python3.7/site-packages/econml/dml/_rlearner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, Y, T, X, W, sample_weight, freq_weight, sample_var, groups, cache_values, inference)\u001b[0m\n\u001b[1;32m    370\u001b[0m                            \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfreq_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_var\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m                            \u001b[0mcache_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m                            inference=inference)\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/econ21340-env/lib/python3.7/site-packages/econml/utilities.py\u001b[0m in \u001b[0;36mm\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrong_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m                 \u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1262\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mto_wrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1263\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1264\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/econ21340-env/lib/python3.7/site-packages/econml/_cate_estimator.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, Y, T, inference, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;31m# call the wrapped fit method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_postfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minference\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/econ21340-env/lib/python3.7/site-packages/econml/_ortho_learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, Y, T, X, W, Z, sample_weight, freq_weight, sample_var, groups, cache_values, inference, only_final, check_input)\u001b[0m\n\u001b[1;32m    686\u001b[0m                         \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                         \u001b[0mfreq_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfreq_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m                         sample_var=sample_var)\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/econ21340-env/lib/python3.7/site-packages/econml/_ortho_learner.py\u001b[0m in \u001b[0;36m_fit_final\u001b[0;34m(self, Y, T, X, W, Z, nuisances, sample_weight, freq_weight, sample_var)\u001b[0m\n\u001b[1;32m    776\u001b[0m                                                                        \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m                                                                        \u001b[0mfreq_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfreq_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m                                                                        sample_var=sample_var))\n\u001b[0m\u001b[1;32m    779\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ortho_learner_model_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/econ21340-env/lib/python3.7/site-packages/econml/dml/_rlearner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, Y, T, X, W, Z, nuisances, sample_weight, freq_weight, sample_var)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mY_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnuisances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         self._model_final.fit(X, T, T_res, Y_res, sample_weight=sample_weight,\n\u001b[0;32m---> 97\u001b[0;31m                               freq_weight=freq_weight, sample_var=sample_var)\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/econ21340-env/lib/python3.7/site-packages/econml/dml/causal_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, T, T_res, Y_res, sample_weight, freq_weight, sample_var)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mY_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mY_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;31m# Fit a doubly robust average effect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_discrete_treatment\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/econ21340-env/lib/python3.7/site-packages/econml/grf/classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, T, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         [estimator.fit(X, T, y[:, [it]], sample_weight=sample_weight, **kwargs)\n\u001b[0;32m---> 37\u001b[0;31m          for it, estimator in enumerate(self.estimators_)]\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/econ21340-env/lib/python3.7/site-packages/econml/grf/classes.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         [estimator.fit(X, T, y[:, [it]], sample_weight=sample_weight, **kwargs)\n\u001b[0;32m---> 37\u001b[0;31m          for it, estimator in enumerate(self.estimators_)]\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/econ21340-env/lib/python3.7/site-packages/econml/grf/classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, T, y, sample_weight)\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \"\"\"\n\u001b[0;32m--> 392\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_alpha_and_pointJ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/econ21340-env/lib/python3.7/site-packages/econml/grf/_base_grf.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, T, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m                                check_input=False)\n\u001b[0;32m--> 388\u001b[0;31m                 for t, s in zip(trees, s_inds))\n\u001b[0m\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/econ21340-env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/econ21340-env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/econ21340-env/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/econ21340-env/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/econ21340-env/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/econ21340-env/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Ns = [1000, 5000, 10000]\n",
    "\n",
    "biasNs = []\n",
    "rmseNs = []\n",
    "coverageNs = []\n",
    "intervalNs = []\n",
    "\n",
    "for N in Ns:\n",
    "    estNs = []\n",
    "    trueATENs = []\n",
    "    evalSetNs = []\n",
    "    for i in range(K):\n",
    "        y, X, trueBetas, featureNames, treatments, cy, ate = dgp(welfare, N=N)\n",
    "        est, X_test = estimate_cf(y, X, treatments)\n",
    "\n",
    "        estNs.append(est)\n",
    "        trueATENs.append(est.ate(X_test)[0])\n",
    "        evalSetNs.append(X_test)\n",
    "\n",
    "    bias, rmse, coverage, interval = evalStats(estNs, trueATENs, evalSetNs)\n",
    "    \n",
    "    biasNs.append(bias)\n",
    "    rmseNs.append(rmse)\n",
    "    coverageNs.append(coverage)\n",
    "    intervalNs.append(interval)"
   ]
  },
  {
   "source": [
    "## (2) Degree of non-linearity in X"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearityLevels = ['full', 'high', 'med', 'low']\n",
    "\n",
    "biasLLs = []\n",
    "rmseLLs = []\n",
    "coverageLLs = []\n",
    "intervalLLs = []\n",
    "\n",
    "for level in linearityLevels:\n",
    "    estLLs = []\n",
    "    trueATELLs = []\n",
    "    evalSetLLs = []\n",
    "    for i in range(K):\n",
    "        y, X, trueBetas, featureNames, treatments, cy, ate = dgp(welfare, linearity=level)\n",
    "        est, X_test = estimate_cf(y, X, treatments)\n",
    "\n",
    "        estLLs.append(est)\n",
    "        trueATELLs.append(est.ate(X_test)[0])\n",
    "        evalSetLLs.append(X_test)\n",
    "\n",
    "    bias, rmse, coverage, interval = evalStats(estLLs, trueATELLs, evalSetLLs)\n",
    "    \n",
    "    biasLLs.append(bias)\n",
    "    rmseLLs.append(rmse)\n",
    "    coverageLLs.append(coverage)\n",
    "    intervalLLs.append(interval)"
   ]
  },
  {
   "source": [
    "## (3) Percentage Treated"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentTreats = [0.1, 0.5, 0.9, 1]\n",
    "\n",
    "biasPTs = []\n",
    "rmsePTs = []\n",
    "coveragePTs = []\n",
    "intervalPTs = []\n",
    "\n",
    "for percent in percentTreats:\n",
    "    estPTs = []\n",
    "    trueATEPTs = []\n",
    "    evalSetPTs = []\n",
    "    for i in range(K):\n",
    "        y, X, trueBetas, featureNames, treatments, cy, ate = dgp(welfare, treatment_probability=percent)\n",
    "        est, X_test = estimate_cf(y, X, treatments)\n",
    "\n",
    "        estPTs.append(est)\n",
    "        trueATEPTs.append(est.ate(X_test)[0])\n",
    "        evalSetPTs.append(X_test)\n",
    "\n",
    "    bias, rmse, coverage, interval = evalStats(estPTs, trueATEPTs, evalSetPTs)\n",
    "    \n",
    "    biasPTs.append(bias)\n",
    "    rmsePTs.append(rmse)\n",
    "    coveragePTs.append(coverage)\n",
    "    intervalPTs.append(interval)"
   ]
  },
  {
   "source": [
    "## (4) Overlap"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlapTypes = [True, False]\n",
    "\n",
    "biasOTs = []\n",
    "rmseOTs = []\n",
    "coverageOTs = []\n",
    "intervalOTs = []\n",
    "\n",
    "for overlap in overlapTypes:\n",
    "    estOTs = []\n",
    "    trueATEOTs = []\n",
    "    evalSetOTs = []\n",
    "    for i in range(K):\n",
    "        y, X, trueBetas, featureNames, treatments, cy, ate = dgp(welfare, overlap=overlap)\n",
    "        est, X_test = estimate_cf(y, X, treatments)\n",
    "\n",
    "        estOTs.append(est)\n",
    "        trueATEOTs.append(est.ate(X_test)[0])\n",
    "        evalSetOTs.append(X_test)\n",
    "\n",
    "    bias, rmse, coverage, interval = evalStats(estOTs, trueATEOTs, evalSetOTs)\n",
    "    \n",
    "    biasOTs.append(bias)\n",
    "    rmseOTs.append(rmse)\n",
    "    coverageOTs.append(coverage)\n",
    "    intervalOTs.append(interval)"
   ]
  },
  {
   "source": [
    "## (5) Treatment Effect Heterogeneity Level"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heterogeneityLevels = [0, 2, 4, 8]\n",
    "\n",
    "biasHLs = []\n",
    "rmseHLs = []\n",
    "coverageHLs = []\n",
    "intervalHLs = []\n",
    "\n",
    "for heterogeneity in heterogeneityLevels:\n",
    "    estHLs = []\n",
    "    trueATEHLs = []\n",
    "    evalSetHLs = []\n",
    "    for i in range(K):\n",
    "        if heterogeneity == 0:\n",
    "            y, X, trueBetas, featureNames, treatments, cy, ate = dgp(welfare, effect_type='homogeneous')\n",
    "        else:\n",
    "            y, X, trueBetas, featureNames, treatments, cy, ate = dgp(welfare, heterogeneous_select=heterogeneity)\n",
    "\n",
    "        est, X_test = estimate_cf(y, X, treatments)\n",
    "\n",
    "        estHLs.append(est)\n",
    "        trueATEHLs.append(est.ate(X_test)[0])\n",
    "        evalSetHLs.append(X_test)\n",
    "\n",
    "    bias, rmse, coverage, interval = evalStats(estHLs, trueATEHLs, evalSetHLs)\n",
    "    \n",
    "    biasHLs.append(bias)\n",
    "    rmseHLs.append(rmse)\n",
    "    coverageHLs.append(coverage)\n",
    "    intervalHLs.append(interval)"
   ]
  },
  {
   "source": [
    "## (6) Treatment Type (Continuous vs. Discrete)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatmentTypes = ['binary', 'continuous']\n",
    "\n",
    "biasTTs = []\n",
    "rmseTTs = []\n",
    "coverageTTs = []\n",
    "intervalTTs = []\n",
    "\n",
    "for treatment_type in treatmentTypes:\n",
    "    estTTs = []\n",
    "    trueATETTs = []\n",
    "    evalSetTTs = []\n",
    "    for i in range(K):\n",
    "        y, X, trueBetas, featureNames, treatments, cy, ate = dgp(welfare, treatment_type=treatment_type)\n",
    "        est, X_test = estimate_cf(y, X, treatments)\n",
    "\n",
    "        estTTs.append(est)\n",
    "        trueATETTs.append(est.ate(X_test)[0])\n",
    "        evalSetTTs.append(X_test)\n",
    "\n",
    "    bias, rmse, coverage, interval = evalStats(estTTs, trueATETTs, evalSetTTs)\n",
    "    \n",
    "    biasTTs.append(bias)\n",
    "    rmseTTs.append(rmse)\n",
    "    coverageTTs.append(coverage)\n",
    "    intervalTTs.append(interval)"
   ]
  },
  {
   "source": [
    "## (7) Alignment"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is to implement / have running state of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "effect_type=\"heterogeneous\"\n",
    "effect_homogeneous=10\n",
    "effect_heterogeneous=2\n",
    "# treatment_type=\"continuous\"\n",
    "treatment_type=\"binary\"\n",
    "treatment_probability=0.5\n",
    "heterogeneous_select=4\n",
    "order=3\n",
    "linearity=\"med\"\n",
    "N=1000\n",
    "overlap=True\n",
    "overlap_percent=0.5\n",
    "\n",
    "featureNames = list(welfare.columns)\n",
    "\n",
    "importantFeatureNames = ['wrkstat', 'race', 'year', 'hrs1', 'income', 'occ80', 'id', 'educ'] # top 8 important features based on Shapley visualization from \n",
    "importantFeatureIndices = []\n",
    "for name in importantFeatureNames:\n",
    "    importantFeatureIndices.append(featureNames.index(name)) \n",
    "\n",
    "# error terms\n",
    "error = np.random.normal(size=(N,1))\n",
    "\n",
    "# data generation\n",
    "cov = welfare.cov()\n",
    "means = welfare.mean(axis=0)\n",
    "X = np.random.multivariate_normal(means.values, cov, size=N, check_valid='warn', tol=1e-8)\n",
    "\n",
    "# linearity specification\n",
    "if linearity != 'full':\n",
    "    select = 0 # select n most important features for interactions and polynomials\n",
    "    poly = PolynomialFeatures(degree=order, interaction_only=False, include_bias=False)\n",
    "\n",
    "    if linearity == \"high\": \n",
    "        select = 2\n",
    "    elif linearity == \"med\": \n",
    "        select = 4\n",
    "    elif linearity == \"low\": \n",
    "        select = 8\n",
    "    else: # if some typo, assume baseline of high\n",
    "        select = 2\n",
    "\n",
    "    poly.fit(X[:, importantFeatureIndices[:select]])\n",
    "    fullData = poly.transform(X[:, importantFeatureIndices[:select]])\n",
    "    fullNames = poly.get_feature_names(input_features=importantFeatureNames[:select])\n",
    "    higherData = fullData[:, -(fullData.shape[1] - select):] # select only higher order\n",
    "    higherNames = fullNames[-(len(fullNames) - select):]\n",
    "\n",
    "    X = np.append(X, higherData, axis=1) \n",
    "    featureNames.extend(list(higherNames))\n",
    "\n",
    "# treatment type\n",
    "if treatment_type == \"binary\":\n",
    "    # randomly assigned treatments with propensity treatment_probability\n",
    "    treatments = np.random.choice([0, 1], size=N, p=[1 - treatment_probability, treatment_probability]).reshape((-1, 1))\n",
    "    if not overlap:\n",
    "        forced = random.sample(list(np.arange(treatments.shape[0])), int(treatments.shape[0] * overlap_percent))\n",
    "        treatments[forced] = 0\n",
    "    treated = treatments > 0\n",
    "    \n",
    "    # generate counterfactual treatment indicator vector\n",
    "    c_treatments = deepcopy(treatments)\n",
    "    c_treatments[treatments == 0] = 1\n",
    "    c_treatments[treatments == 1] = 0\n",
    "\n",
    "else:\n",
    "    treatments = np.random.uniform(size=(N, 1))\n",
    "    if not overlap:\n",
    "        forced = random.sample(list(np.arange(treatments.shape[0])), int(treatments.shape[0] * overlap_percent))\n",
    "        treatments[forced] = 0\n",
    "    treated = treatments > 0.5\n",
    "    c_treatments = deepcopy(treatments)\n",
    "    # to-do\n",
    "    c_treatments[treatments > 0] = 0\n",
    "    c_treatments[treatments == 0] = treatments.mean()\n",
    "    \n",
    "# treatment effect\n",
    "if effect_type == \"homogeneous\":\n",
    "\n",
    "    T = treatments*effect_homogeneous\n",
    "    CT = c_treatments*effect_homogeneous\n",
    "    \n",
    "else: # heterogeneous\n",
    "    # heterogeneous treatment is effect 1 + effect * (sum of first heterogeneous_select important variables)\n",
    "    heterogeneousIndices = importantFeatureIndices[:heterogeneous_select]\n",
    "    \n",
    "    T = 1 + (2*(X[:, heterogeneousIndices].sum(axis=1)))*treatments.ravel()\n",
    "    T = T.reshape(-1, 1)\n",
    "    T[~treated] = np.zeros((~treated).sum())\n",
    "    \n",
    "    CT = 1 + (2*(X[:, heterogeneousIndices].sum(axis=1)))*c_treatments.ravel()\n",
    "    CT = CT.reshape(-1, 1)\n",
    "    CT[treated] = np.zeros((treated).sum()) # everyone that was treated goes to untreated in counterfactual\n",
    "    \n",
    "\n",
    "betas = np.random.normal(size=X.shape[1]).reshape(-1,1)\n",
    "y = T + X@betas + error\n",
    "cy = CT + X@betas + error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.720148792484203"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:, heterogeneousIndices].mean(axis=0).sum() # average across the used columns to check ATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.43845628547201"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = y[treated] - cy[treated] # the treated\n",
    "untmp = cy[~treated] - y[~treated] # the untreated\n",
    "ate = (tmp.mean() + untmp.mean())/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X, trueBetas, featureNames, treatments, cy, ate = dgp(welfare, N=36501, order=3, treatment_probability=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "est, X_test = estimate_cf(y, X, treatments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python377jvsc74a57bd0254ebfd476bc3fc79ad5c8b426190fe7c8c50894e6b0352342e1dad3387876d5",
   "display_name": "Python 3.7.7 64-bit ('econ21340-env': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}