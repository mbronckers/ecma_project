{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import dowhy\n",
    "from dowhy import CausalModel\n",
    "import dowhy.datasets\n",
    "\n",
    "import econml\n",
    "import warnings\n",
    "from copy import deepcopy\n",
    "\n",
    "#from sklearn.preprocessing import LabelEncoder, normalize\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from econml.dml import CausalForestDML\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def fullDisplay():\n",
    "    pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "\n",
    "def defaultDisplay():\n",
    "    pd.reset_option('^display.', silent=True)\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>id</th>\n",
       "      <th>wrkstat</th>\n",
       "      <th>hrs1</th>\n",
       "      <th>hrs2</th>\n",
       "      <th>evwork</th>\n",
       "      <th>occ</th>\n",
       "      <th>prestige</th>\n",
       "      <th>wrkslf</th>\n",
       "      <th>wrkgovt</th>\n",
       "      <th>...</th>\n",
       "      <th>earnrs_miss</th>\n",
       "      <th>income_miss</th>\n",
       "      <th>rincome_miss</th>\n",
       "      <th>income86_miss</th>\n",
       "      <th>partyid_miss</th>\n",
       "      <th>polviews_miss</th>\n",
       "      <th>attblack</th>\n",
       "      <th>attblack_miss</th>\n",
       "      <th>w</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.004845</td>\n",
       "      <td>0.005228</td>\n",
       "      <td>1</td>\n",
       "      <td>135</td>\n",
       "      <td>0.005641</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005440</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005055</td>\n",
       "      <td>0.005228</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>0.006538</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004080</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.004845</td>\n",
       "      <td>0.005228</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>0.006538</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002040</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005055</td>\n",
       "      <td>0.005228</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>0.004615</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004080</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.005055</td>\n",
       "      <td>0.005228</td>\n",
       "      <td>1</td>\n",
       "      <td>211</td>\n",
       "      <td>0.005171</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004080</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36496</th>\n",
       "      <td>15</td>\n",
       "      <td>2040</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005055</td>\n",
       "      <td>0.005228</td>\n",
       "      <td>0</td>\n",
       "      <td>211</td>\n",
       "      <td>0.005171</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004080</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36497</th>\n",
       "      <td>15</td>\n",
       "      <td>2041</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005055</td>\n",
       "      <td>0.005228</td>\n",
       "      <td>0</td>\n",
       "      <td>211</td>\n",
       "      <td>0.005171</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006120</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36498</th>\n",
       "      <td>15</td>\n",
       "      <td>2042</td>\n",
       "      <td>7</td>\n",
       "      <td>0.004845</td>\n",
       "      <td>0.005228</td>\n",
       "      <td>1</td>\n",
       "      <td>211</td>\n",
       "      <td>0.005171</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004080</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36499</th>\n",
       "      <td>15</td>\n",
       "      <td>2043</td>\n",
       "      <td>7</td>\n",
       "      <td>0.005935</td>\n",
       "      <td>0.005228</td>\n",
       "      <td>1</td>\n",
       "      <td>211</td>\n",
       "      <td>0.005171</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005021</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36500</th>\n",
       "      <td>15</td>\n",
       "      <td>2044</td>\n",
       "      <td>7</td>\n",
       "      <td>0.004845</td>\n",
       "      <td>0.005228</td>\n",
       "      <td>1</td>\n",
       "      <td>211</td>\n",
       "      <td>0.005171</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008160</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36501 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year    id  wrkstat      hrs1      hrs2  evwork  occ  prestige  wrkslf  \\\n",
       "0         0     1        7  0.004845  0.005228       1  135  0.005641       2   \n",
       "1         0     2        1  0.005055  0.005228       0  106  0.006538       2   \n",
       "2         0     3        7  0.004845  0.005228       1   99  0.006538       2   \n",
       "3         0     4        3  0.005055  0.005228       0  142  0.004615       2   \n",
       "4         0     5        8  0.005055  0.005228       1  211  0.005171       2   \n",
       "...     ...   ...      ...       ...       ...     ...  ...       ...     ...   \n",
       "36496    15  2040        3  0.005055  0.005228       0  211  0.005171       2   \n",
       "36497    15  2041        3  0.005055  0.005228       0  211  0.005171       2   \n",
       "36498    15  2042        7  0.004845  0.005228       1  211  0.005171       2   \n",
       "36499    15  2043        7  0.005935  0.005228       1  211  0.005171       2   \n",
       "36500    15  2044        7  0.004845  0.005228       1  211  0.005171       2   \n",
       "\n",
       "       wrkgovt  ...  earnrs_miss  income_miss  rincome_miss  income86_miss  \\\n",
       "0            2  ...            0            0             0              0   \n",
       "1            2  ...            0            0             1              0   \n",
       "2            2  ...            0            0             0              0   \n",
       "3            0  ...            0            0             1              0   \n",
       "4            1  ...            0            0             0              0   \n",
       "...        ...  ...          ...          ...           ...            ...   \n",
       "36496        2  ...            0            0             1              1   \n",
       "36497        2  ...            0            0             1              1   \n",
       "36498        2  ...            0            0             0              1   \n",
       "36499        2  ...            0            0             1              1   \n",
       "36500        2  ...            0            0             0              1   \n",
       "\n",
       "       partyid_miss  polviews_miss  attblack  attblack_miss  w  y  \n",
       "0                 0              0  0.005440              0  1  0  \n",
       "1                 0              0  0.004080              0  1  1  \n",
       "2                 0              0  0.002040              0  1  1  \n",
       "3                 0              0  0.004080              0  1  0  \n",
       "4                 0              0  0.004080              0  1  0  \n",
       "...             ...            ...       ...            ... .. ..  \n",
       "36496             0              0  0.004080              0  1  0  \n",
       "36497             0              0  0.006120              0  1  1  \n",
       "36498             0              0  0.004080              0  0  0  \n",
       "36499             0              0  0.005021              1  1  0  \n",
       "36500             0              0  0.008160              0  1  1  \n",
       "\n",
       "[36501 rows x 122 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# w = 0 means the question had \"assistance\", w = 1 means the question had \"welfare\"\n",
    "# y = 0 means the responder said no, y = 1 means yes\n",
    "welfare_raw = pd.read_csv(\"Data/welfare_clean.csv\", low_memory=False)\n",
    "labels = welfare_raw['y'].values\n",
    "treatments = welfare_raw['w']\n",
    "treatments = treatments.replace({0:1, 1:0}) # we want 1 to be assistance, and 0 to be welfare, so if the TE is positive then it means people responded favorably to assistance\n",
    "welfare_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'educ'}>]], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "welfaredf = pd.DataFrame(welfare_raw)\n",
    "welfaredf.hist(column = 'educ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a kernel density model using GridSearchCV to determine the best parameter for bandwidth\n",
    "bandwidth_params = {'bandwidth': np.arange(0.01,1,0.05)}\n",
    "grid_search = GridSearchCV(KernelDensity(), bandwidth_params)\n",
    "grid_search.fit(welfare_raw)\n",
    "kde = grid_search.best_estimator_\n",
    "\n",
    "# # Generate/sample 8 new faces from this dataset\n",
    "# new_faces = kde.sample(8, random_state=rand_state)\n",
    "\n",
    "# # Show a sample of 8 original face images and 8 generated faces derived from the faces dataset\n",
    "# fig,ax = plt.subplots(nrows=2, ncols=8,figsize=(18,6),subplot_kw=dict(xticks=[], yticks=[]))\n",
    "# for i in np.arange(8):\n",
    "#     ax[0,i].imshow(X[10*i,:].reshape(64,64),cmap=plt.cm.gray)   \n",
    "#     ax[1,i].imshow(new_faces[i,:].reshape(64,64),cmap=plt.cm.gray)    \n",
    "# ax[0,3].set_title('Original Data',fontsize=20)\n",
    "# ax[1,3].set_title('Synthetic Data',fontsize=20)\n",
    "# fig.subplots_adjust(wspace=.1)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde\n",
    "import joblib\n",
    "joblib.dump(grid_search, 'Data/test_GridSearch_vee.pkl')\n",
    "joblib.dump(kde, 'Data/test_kde_vee.pkl')\n",
    "test_kde = joblib.load('Data/test_kde_vee.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BETA = 10 \n",
    "\n",
    "df = data['df']\n",
    "X = df.drop(['y'], axis=1)\n",
    "Y = df['y']\n",
    "T = df['v0']\n",
    "X_train, X_test, Y_train, Y_test, T_train, T_test = train_test_split(X, Y, T, test_size=0.2)\n",
    "        \n",
    "# specify hyperparams of model\n",
    "est = CausalForest(criterion='mse', n_estimators=1000,       \n",
    "                        min_samples_leaf=1, \n",
    "                        max_depth=100, max_samples=0.5,\n",
    "                        honest=True, inference=True)\n",
    "\n",
    "# fit model\n",
    "est.fit(X_train, T_train, Y_train)\n",
    "\n",
    "predict, sigma = est.predict_and_var(X_test)\n",
    "\n",
    "est, predict, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_cf(y, X, treatments, test_size=0.2, criterion='mse', cv=5):\n",
    "    # split data into train and test sets \n",
    "    X_train, X_test, Y_train, Y_test, T_train, T_test = train_test_split(X, y, treatments, test_size=test_size)\n",
    "        \n",
    "    # specify hyperparams of model\n",
    "    est = CausalForestDML(criterion='het', \n",
    "                            n_estimators=1000,       \n",
    "                            max_samples=0.5,\n",
    "                            discrete_treatment=True,\n",
    "                            honest=True,\n",
    "                            inference=True,\n",
    "                            cv=cv,\n",
    "                            )\n",
    "    # fit model\n",
    "    est.fit(Y_train, T_train, X=X_train, W=None)\n",
    "        \n",
    "    return est, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_general, X_test_general = estimate_cf(labels, welfare, treatments)\n",
    "est_general.ate_inference(X_test_general)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
