%
\documentclass[12pt]{article}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{pdflscape}
\usepackage{tabularx}
\usepackage{longtable}
\usepackage{array}
\usepackage{dsfont}
\usepackage{float}
\usepackage{booktabs}
\usepackage{marvosym}
\usepackage{multirow}
\usepackage{pdflscape}
\usepackage[hyphenbreaks]{breakurl}
\usepackage[hyphens]{url}
\usepackage{setspace}
\usepackage{epigraph}
\usepackage{bm}
\usepackage{textcomp}
\usepackage{bbm}
\usepackage{verbatim}
\usepackage{subcaption}
\usepackage{caption}
\usepackage[shortlabels]{enumitem}
\usepackage{graphicx}
\usepackage{natbib,hyperref}
\setlength{\epigraphrule}{0pt}
\setlength\parindent{1cm}
\renewcommand{\baselinestretch}{1}
\renewcommand*{\arraystretch}{1.2}

\setcounter{MaxMatrixCols}{10}

\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}

\newcommand{\E}{\mathrm{E}}
\newcommand{\BLP}{\mathrm{BLP}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\Corr}{\mathrm{Corr}}
\newcommand{\Prob}{\mathrm{P}}
\newcommand{\N}{\text{N}}

\topmargin=-1.5cm \textheight=23cm \oddsidemargin=-0.0cm
\evensidemargin=-0.0cm \textwidth=16.5cm
\newtheorem{ass}{Assumption}
\newtheorem{definit}{Definition}
\newtheorem{prop}{Proposition}
\newtheorem{thm}{Theorem}
\newtheorem{lem}{Lemma}
\newtheorem{conj}{Conjecture}
\newtheorem{cor}{Corollary}
\newtheorem{rem}{Remark}
\renewcommand{\thesubsection}{\arabic{section}.\arabic{subsection}}
\renewcommand{\thesubsubsection}{\arabic{section}.\arabic{subsection}.\arabic{subsubsection}}

\newcommand\independent{\protect\mathpalette{\protect\independenT}{\perp}}
\def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}

%Figure path
\def \figroot{stata/out/}
\def \tabroot{stata/out/}

\usepackage{epsfig,hyperref}

\hypersetup{
	pdftitle={ECMA31330 Final Project},    % title
	pdfauthor={Bronckers.Song.Zhang},     % author/Users/veronica/Documents/ECON21110/Final Project/ECON21110_FinalProject.tex
	pdfnewwindow=true,      % links in new window
	colorlinks=true,       % false: boxed links; true: colored links
	linkcolor=blue,          % color of internal links
	citecolor=red,        % color of links to bibliography
	filecolor=black,      % color of file links
	urlcolor=blue           % color of external links
}

\allowdisplaybreaks


\begin{document}
\begin{titlepage}
    \begin{center}
        \vspace*{1cm}
        \LARGE
        \textbf{PAPER TITLE Blah Blah\\ Estimating Reaction to Welfare\\ Using Causal Forests\\}
        \vspace{0.5cm}
        \Large
        ECMA 31330 Final Project \\ 
        \vspace{0.8cm}
        \large
        Spring 2021
        \vfill
        \vspace{5cm}
        \textbf{Max Bronckers \\ Veronica Song \\ Dustin Zhang}
    \end{center}
\end{titlepage}


\section{Introduction} 
There has been an increasing adoption of Machine Learning (ML) methods in
economics for algorithmic approaches to causal inference. Whereas initially the
ML methods were avoided due to uncertainty in its consistency, normality, and
efficiency, major developments in methodology has allowed a stable large-sample
confidence interval to be constructed around treatment effect estimates
conditional on multiple covariates.\cite{athey2019ML} One such method is the
Bayesian Additive Regression Trees (BART) used by Green and Kern (2012), which
allows heterogeneous treatment effects to be modeled flexibly. Using a Markov
Chain Monte Carlo (MCMC) algorithm that derives effects from the posterior mean
and interval instead of pre-specified tree parameters, BART has a much smoother
and adaptive structure than traditional OLS or single tree models popular in
economics, and is also resilient to problems with
overfitting.\cite{greenkern2012} However, despite its excellent predictive
capacity, BART lacks an asymptotic explanation of the estimates and are thus
difficult for causal inference and application. Though recent work by Ročková
and Saha (2018) suggests modifications to BART that may allow concentration of
the posterior mean around the true mean, the construction of an asymptotic
theory of BART estimates is still an ongoing effort. \cite{rockova2018theory}.
Another such method is the causal forests proposed by Wager and Athey (2017),
which estimates are asymptotically gaussian and unbiased to allow proper
confidence intervals to be constructed around the treatment effect. The
construction of adequate confidence intervals is especially relevant in policy
applications, as consistent estimates can be produced for the treatment
group.\cite{atheywager2019} \\ 

In this paper, we compare the aforementioned two popular ML tools in
heterogenous treatment effects estimation among survey responders using an
empirical dataset. Specifically, we aim to compare uses of BART versus Causal
Forests, using OLS estimates of heterogeneous treatment effects as a benchmark.
To measure the stigma around the word "welfare", we take a survey data of
individual perception on public spending and find the impact of the question
phrasing on the responses. In order to uncover the heterogenous effects of the
question phrasing based on a suite of socioeconomic backgrounds of the
respondent, Green and Kern utilizes BART. Given the theoretical shortcomings of
BART, we aim to make causal forest estimates and compare it to the authors'
findings. The first section of this paper examines the causal forest under
different parameters of a synthetic DGP that resembles our empirical dataset.
Here, taking our DGP as a ground truth, we aim to assess conditions under which
causal forest performs well or poorly and thus evaluate it against our empirical
dataset. In the second section, we fit a causal forest model on the empirical
data and compare our estimates against BART estimates of conditional average
treatment effect (CATE) obtained by Green and Kern. \\


\section{Discussion of Data?} 


\newpage
\bibliographystyle{abbrv}
\bibliography{Bibliography}


\end{document}



















