%
\documentclass[12pt]{article}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{pdflscape}
\usepackage{tabularx}
\usepackage{longtable}
\usepackage{array}
\usepackage{dsfont}
\usepackage{float}
\usepackage{booktabs}
\usepackage{marvosym}
\usepackage{multirow}
\usepackage{pdflscape}
\usepackage[hyphenbreaks]{breakurl}
\usepackage[hyphens]{url}
\usepackage{setspace}
\usepackage{epigraph}
\usepackage{bm}
\usepackage{textcomp}
\usepackage{bbm}
\usepackage{verbatim}
\usepackage{subcaption}
\usepackage[format=hang,font={small,bf}]{caption}
\usepackage[shortlabels]{enumitem}
\usepackage{graphicx}
\usepackage{natbib,hyperref}
\setlength{\epigraphrule}{0pt}
\setlength\parindent{1cm}
\renewcommand{\baselinestretch}{1}
\renewcommand*{\arraystretch}{1.2}

\setcounter{MaxMatrixCols}{10}

\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}

\newcommand{\E}{\mathrm{E}}
\newcommand{\BLP}{\mathrm{BLP}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\Corr}{\mathrm{Corr}}
\newcommand{\Prob}{\mathrm{P}}
\newcommand{\N}{\text{N}}

\topmargin=-1.5cm \textheight=23cm \oddsidemargin=-0.0cm
\evensidemargin=-0.0cm \textwidth=16.5cm
\newtheorem{ass}{Assumption}
\newtheorem{definit}{Definition}
\newtheorem{prop}{Proposition}
\newtheorem{thm}{Theorem}
\newtheorem{lem}{Lemma}
\newtheorem{conj}{Conjecture}
\newtheorem{cor}{Corollary}
\newtheorem{rem}{Remark}
\renewcommand{\thesubsection}{\arabic{section}.\arabic{subsection}}
\renewcommand{\thesubsubsection}{\arabic{section}.\arabic{subsection}.\arabic{subsubsection}}

\newcommand\independent{\protect\mathpalette{\protect\independenT}{\perp}}
\def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}

%Figure path
\def \figroot{stata/out/}
\def \tabroot{stata/out/}

\usepackage{epsfig,hyperref}

\hypersetup{
	pdftitle={ECMA31330 Final Project},    % title
	pdfauthor={Bronckers.Song.Zhang},     % author/Users/veronica/Documents/
	pdfnewwindow=true,      % links in new window
	colorlinks=true,       % false: boxed links; true: colored links
	linkcolor=blue,          % color of internal links
	citecolor=red,        % color of links to bibliography
	filecolor=black,      % color of file links
	urlcolor=blue           % color of external links
}

\allowdisplaybreaks


\begin{document}
\begin{titlepage}
    \begin{center}
        \vspace*{1cm}
        \LARGE
        \textbf{PAPER TITLE Blah Blah\\ Estimating Reaction to Welfare\\ Using Causal Forests\\}
        \vspace{0.5cm}
        \Large
        ECMA 31330 Final Project \\ 
        \vspace{0.8cm}
        \large
        Spring 2021
        \vfill
        \vspace{5cm}
        \textbf{Max Bronckers \\ Veronica Song \\ Dustin Zhang}
    \end{center}
\end{titlepage}


\section{Introduction} 
There has been an increasing adoption of Machine Learning (ML) methods in
economics for algorithmic approaches to causal inference. Whereas initially the
ML methods were avoided due to uncertainty in its consistency, normality, and
efficiency, major developments in methodology has allowed a stable large-sample
confidence interval to be constructed around treatment effect estimates
conditional on multiple covariates.\cite{athey2019ML} \\

One such method is the Bayesian Additive Regression Trees (BART) used by Green and Kern (2012), which
allows heterogeneous treatment effects to be modeled flexibly. Using a Markov
Chain Monte Carlo (MCMC) algorithm that derives effects from the posterior mean
and interval instead of pre-specified tree parameters, BART has a much smoother
and adaptive structure than traditional OLS or single tree models popular in
economics, and is also resilient to problems with
overfitting.\cite{greenkern2012} However, despite its excellent predictive
capacity, BART lacks an asymptotic explanation of the estimates and are thus
difficult for causal inference and application. Though recent work by Ročková
and Saha (2018) suggests modifications to BART that may allow asypmtotic concentration of
the posterior mean around the true mean, the construction of an asymptotic
theory of BART estimates is still an ongoing effort.\cite{rockova2018theory}.
Another such method is the causal forests proposed by Wager and Athey (2017),
which estimates are asymptotically gaussian and unbiased to allow proper
confidence intervals to be constructed around the treatment effect. The
construction of adequate confidence intervals is especially relevant in policy
applications, as consistent estimates can be produced for the treatment
group.\cite{atheywager2019} \\ 

In this paper, we compare the aforementioned two popular ML tools in
heterogenous treatment effects estimation among survey responders using an
empirical dataset. Specifically, we aim to compare uses of BART versus Causal
Forests, using OLS estimates of heterogeneous treatment effects as a benchmark.
To measure the stigma around the word "welfare", we take a survey data of
individual perception on public spending and find the impact of the question
phrasing on the responses. In order to uncover the heterogenous effects of the
question phrasing based on a suite of socioeconomic backgrounds of the
respondent, Green and Kern utilizes BART. Given the theoretical shortcomings of
BART, we aim to make causal forest estimates and compare it to the authors'
findings. The first section of this paper fits a causal forest model on the welfare data and compares our estimates against BART estimates of conditional average treatment effect (CATE) obtained by Green and Kern. However, since in the empirical data we are unable to distinguish the ground truth, we are confined to comparison using interval length and RMSE. In the second section, we examine the causal forest approach under different parameters of a synthetic DGP. Here, taking our DGP as ground truth, we aim to assess conditions under which the causal forest performs well or poorly and check whether these conditions hold in our empirical dataset. \\ 

\section{Causal Forest Estimates of CATE in Welfare Dataset} 

\subsection{Discussion of data and motivation for research} 
In our analysis below, we use a survey experiment from GSS which is also utilized by Green and Kern to investigate interactions between treatment and covariates that may lead to treatment effect heterogeneity. The experiment was conducted in the mid-1980s by GSS to study the negative sentiment Americans carry toward government programs labeled as "welfare". Due to associations with racial connotations and poorly managed welfare programs, respondents were found much more likely to endorse government spending for "the poor" than for public "welfare".\cite{rasinski1989}\\

Using BART, Green and Kern illustrates the extent to which such reaction to the question wording as "welfare" varies based on the respondents' background characteristics such as years of education, race, or political alignment. BART has been a popular choice for heterogeneous treatment effect modeling, as its estimates require little parameter tuning, allow accurate detection of interactions between covariates, and are much smoother than those of single tree models. Each individual tree in the forest has only a small effect on the model, by assuming a prior distribution over the tree parameters.\cite{Chipman2010} Such lack of any individual influential trees allow regular model fit of the BART set up. Then, a MCMC algorithm is used to sample tree parameters iteratively from the posterior distribution as the model is fit. Though this assumption of prior distribution and back-fitting algorithm allows BART to be relatively invariant across, in the presence of confounding variables and treatment effect heterogeneity, such regularization may severely bias the treatment effect estimates.\cite{CarvalhoHahnMurray} Moreover, BART estimates still lack theoretical explanation on its asymptotic concentration, making the construction of adequate confidence intervals challenging. 

\subsection{Causal forests and model assumptions} 
For these reasons, we choose to investigate causal forests to estimate the the treatment effect of question wording on welfare program support. Just like BART, causal forests is fit to model non-linear relationships and interactions between covariates. One advantage that causal forests carry over BART is that under weak assumptions, the estimate are asymptotically standard normal distributed with Gaussian confidence intervals.\cite{atheywager2019}. Put in context of economic policy, the presence of an asymptotic theory allows hypothesis testing regarding treatment results and thus aids policy decisions to be made. \\

Causal forests are a specific form of generalized random forests (GRF), which uses adaptive sample splitting criterion taking into account the MSE. To avoid overfitting and reduce bias in the estimates, we also ensure that the tree is 'honest' - the subsample with which we grow a tree is disparate from the subsample with which we drop down and obtain predictions. 
Additionally, we also note that although causal forests uncover heterogeneous treatment effects with valid confidence intervals for statistical inference, it does not necessarily address the affect of confounding due to the regularization on our trees. The terminal leaves of our tree are not homogenous across covariates for the sake of lowering variance and thus increasing precision, but with confounding within the leaves, we cannot guarantee that our treatment effect estimates will be unbiased. We thus use the Double/Debiased Machine Learning method (DML) for causal forests proposed by Chernozhukov et al. (2016) that uses orthogonalized treatment on covariates to estimate the treatment effect.\cite{DML} We achieve this through the \textit{CausalForestDML} function. In our model, we use 80\% of the welfare data to build our tree and estimate treatment effects on the rest with a 5-fold CV for parameters of the model. \\ 

\subsection{Results of analysis and explanation}
We first investigate the average treatment effects (ATE) without conditioning on any covariates for possible effect heterogeneity. We obtain an ATE of 0.336, with a standard deviation of 0.049 and a 95\% confidence interval of (0.256, 0.416). Green and Kern (2012) identified seven variables to condition the treatment effects on: \textit{party identification, political views, age, education, negative attitude towards Blacks}, and \textit{survey year}. Figure 1 displays the CATE estimates obtained by the causal forest model conditional on each of the seven variables. The blue areas represent the 95\% confidence intervals of our estimates. \\

The top two graphs represents CATE as a function of party identification and self-identified political alignment from liberal to conservative. We see around 5 and 3 percentage points difference in the effect of question wording on support for welfare spending between strong Republicans-Democrats and Conservative-Liberals, respectively, controlling for all other covariates. Conservatives and strong Republicans are more likely to be affected by the framing of the survey question as for welfare. The treatment effect conditional on age, on the other hand, is greatest for those in their 30-40s, and diminishes past that age group. The negative bias toward Blacks has a less pronounced moderation on the treatment effect than the BART estimates.  We note that the trends in CATE estimates obtained via causal forest are generally similar to those obtained using BART for most of the covariate groups except education. There seems to be an increasing effect of question wording as the responded receives greater years of education, with the effect peaking at around 11-13 years (with college education). Whereas Green and Kern found no distinct moderation of treatment effects based on education, we find that there is around 5 percentage point difference in treatment effect estimates between those who received no education and those who received post-Graduate education. This indicates that more educated individuals respond more favorably to the question worded as 'assistance to the poor'. Lastly, we examine that change in CATE through time (survey year) and find that the treatment effect was strongest during years 1993-1996. Our results once again largely agree with the results obtained through BART, and illustrate that response to "welfare" is highly associated with the respondent's personal background characteristics. \\

We note that our CATE estimates from causal forest are on average lower than those of BART. The higher estimates of the BART estimates can be attributed to the regularization-induced confounding (RIC) identified by Hahn, Murray, and Carvalho (2019).\cite{CarvalhoHahnMurray} The treatment effect in BART is obtained by taking the conditional expectation of the outcome conditional on treatment and certain covariates: $E[Y|x,Z = 1] - E[Y|x,Z = 0]$, which in the presence of confounding in finite sample size, outcome may be dependent mostly on x rather than the treatment Z. RIC thus states that the obtained CATEs are heavily dependent on the regularization by the prior distribution in samples of defined sizes. \\

Figure 2 shows the overall presence of treatment effect heterogeneity in the sample. The histogram shows that treatment effect ranges from 10 percentage points to 52 percentage points, with the median estimated CATE of 34 percentage points. We note that compared to the BART median of 37 percentage points, we again obtain lower estimates on average. All estimates of CATE were positive, indicating that although the degrees of the response varies based on personal background covariates, all respondents react more favorably to a question framed for 'the poor' than for 'welfare'. \\

\textbf{Add Interpretation of results, Comparison to BART (Bias, RMSE, Coverage, Int length)?? TBD} 

\subsection{Suggestions for further analysis}
The causal forests approach also allows us to gauge covariate importance by calculating SHAP values, as indicated in figure 3.  We note that aside from the covariates estimated by Green and Kern, we find that variables as work status and racial backgrounds are also significant in the model. Although in this paper we limit the scope of our research to comparisons with the authors' estimates through BART, it may be meaningful in future research to estimate CATE conditional on those variables. 







\section{Testing Parameter Robustness of Causal Forest Estimates on Synthetic DGP} 

The analysis using the welfare data in the section above gives us an interesting real-life application of causal forest method; however, given the lack of ground truth in the empirical situation, we are unable to test the performance of our model in terms of metrics as bias and MSE. In this section, we explore multiple synthetic DGPs to estimate how causal forest performs under different data parameters. 

\subsection{Baseline DGP specification} 

We specify a DGP that resembles our empirical data using a simplified model of N individuals and 120 covariates. Each variable is drawn from a gaussian normal with mean and covariance obtained from the empirical data. We then take each randomly generated covariate and convert to its corresponding form. We assume that the outcome data is generated as: 
\[ Y = B \Gamma + T  \cdot \Theta(X) \tag{1} \label{eq:special}\]
where $\Gamma = X + \sum_{i = 0}^{I} X_i^\omega$ is the full list of covariates including their higher-order interactions with the \textit{i} most important features in the model. This parameter models the degree of linearity in the response surface: \textit{i} features are selected based on SHAP values obtained in the empirical analysis from section 1, and raised to the order of $\omega$ to model non-linear interactions and increased importance of these variables. In our baseline model, we sample N=5000 individuals with parameters $\omega = 3, i = 4$ for `med'-degree linearity. T, our treatment vector, models both binary and continuous treatment assignment; in the binary case, $ T \sim Binomial(n,p)$ where \textit{p} is the probability of receiving treatment. We assume there is a 50\% probability of treatment in the baseline model. In the continuous case, we sample treatment from $T \sim Unif(0,1)$. We model heterogeneous or homogeneous treatment effects through $\Theta(X)$ as defined in equation (2). 
\[
\Theta(X) =  \begin{cases} 
	 \delta_H & {\{H = 0\}} \\ 
	 \delta_H \cdot \big( \sum_{j = 0}^{J} X_j + (\sum_{j = 0}^{J} X_j )^\omega ) & \{ H = 1 \} \\ 
\end{cases} \tag{2} \label{eq:special} \]
Variable \textit{H} indicates whether heterogenous treatment effects are present in the model ($H = 1$), and $\delta_H$ is the size of the effect. We take $\delta_0 = 10, \delta_1 = 2$ in the base model for each homogeneous and heterogeneous cases. $X_j$ parameters are again the \textit{j} most influential features in the empirical data as obtained by SHAP values. \\

\textbf{Also add about ATE stuff etc in baseline DGP} In the following analysis on parameter robustness of the model, we omit CATE estimation due to computational constraints. 

\subsection{DGP parameter modification and expectations of CF performance}

Based on the synthetic DGP above, we test the causal forest model for robustness by modifying the parameters. We then estimate the model \textit{K = 50} times for each parameter value in a range of different parameters. We consider the following dimensions for parameter tweaking: \textit{1) sample size, 2) non-linearity in covariates, 3) percentage treated, 4) overlap, 5) degree of treatment effect heterogeneity, 6) treatment type,} and \textit{7) number of estimators}. 
\subsubsection{Sample size} 
In order to test the asymptotic theory of the causal forest estimates, we test the model performance on multiple sample sizes, $ N = \{1000, 5000, 10000\}$. We expect from standard statistics for both our bias and variance to decrease with increasing sample size, given our estimate converges to the true CATE value. Accordingly, interval length would also decrease.

\subsubsection{Linearity in response surface} 
We tweak the degree of linearity in our covariates to check if the causal forests model is able to handle higher degree relationships and complex interactions between variables. 4 degrees of linearity are explored, specified by \textit{i} in our definition of $\Gamma$ in equation (1) - which corresponds to \textit{full (i = 0), high (i=2), med (i=4), low (i=8)}. As causal forests are expected to be apt at detecting non-linear relationships than traditional treatment effect estimation methods as OLS, we would expect the model to be robust to the introduction of a non-linear response surface. 

\subsubsection{Percentage treated} 

\subsubsection{Overlap}

\subsubsection{Degree of treatment effect heterogeneity} 
Causal forest maximizes 
\cite{athey2018grf}



nonlinenarity incrases in gamma > nonlinearity in Y given Xs 
treat level effect heterogeneity - increasing the effect of treatment heterogeneity 




Causal forests maximizes heterogeneity in its splits. \cite{strimatter}








\subsection{Results and discussion} 

Figure (4) and Table (1) illustrates our results, and we confirm that both bias and RMSE decreases with increasing sample size. 
\begin{table}
\caption{ATE with Sample Size Variation}
\centering
{
\def\sym#1{\ifmmode^{#1}\else\(^{#1}\)\fi}
\resizebox*{\textwidth}{!}{
\begin{tabular}{l|ccccc}
            \textbf{N} &\textbf{Absolute Bias}&\textbf{Relative Bias}&\textbf{RMSE}&\textbf{Coverage}&\textbf{Int. Length}\\
\toprule
\textbf{1000}        &    243.20 &    99999         &     287.11 &     1.0 & 1528.25\\
\addlinespace
\textbf{5000}   &   101.21         &      99999  &       126.20         &       1.0 & 881.80 \\
\addlinespace
\textbf{10000}        &    73.12 &    99999         &     95.11 &     1.0 & 698.63 \\
\bottomrule
\multicolumn{6}{p{\textwidth}}{\footnotesize Relative bias calculated as percentage bias compared to true ATE}\\
\end{tabular}}}
\end{table}



\section{Scribbles}
Expectations of CF performance in different priors (DGPs), for instance normal \& Theoretical justification \\

Discussion of parameters/ What we are doing (how we are tweaking - 5 topics: overlap, alignment, treatment effect heterogeneity, nonlinearity in response/treatment) (TBD)  \\

Present Results (TBD)\\

Discussion of causal forest performance depending on model parameters (how collinearity amongst columns/means/variance in the variables) (TBD) \\




\newpage
\bibliographystyle{abbrv}
\bibliography{Bibliography}

\begin{figure}[h]
\caption{CATE Estimates by Covariate}
\resizebox*{\textwidth}{!}{
	\centering
	\begin{subfigure} [h] {0.45\linewidth}
	\caption{\textbf{Party Identification}}
   	 	\includegraphics[width = \linewidth]{Graphs/s1_partyid.png}
	\end{subfigure}
	\begin{subfigure} [h] {0.45\linewidth}
		\caption{\textbf{Political Views}}
   	 	\includegraphics[width = \linewidth]{Graphs/s1_polyview.png}
	\end{subfigure}}
\resizebox*{\textwidth}{!}{
	\begin{subfigure} [h] {0.45\linewidth}
	\caption{\textbf{Age }}
   	 	\includegraphics[width = \linewidth]{Graphs/s1_age.png}
	\end{subfigure}
	\begin{subfigure} [h] {0.45\linewidth}
		\caption{\textbf{Education Received}}
   	 	\includegraphics[width = \linewidth]{Graphs/s1_educ.png}
	\end{subfigure}}
\resizebox*{\textwidth}{!}{
	\begin{subfigure} [h] {0.45\linewidth}
	\caption{\textbf{Attitude Toward Blacks}}
   	 	\includegraphics[width = \linewidth]{Graphs/s1_attblack.png}
	\end{subfigure}
	\begin{subfigure} [h] {0.45\linewidth}
		\caption{\textbf{Survey Year}}
   	 	\includegraphics[width = \linewidth]{Graphs/s1_year.png}
	\end{subfigure}}
\end{figure} 

\begin{figure}[h]
\caption{Histogram of CATE Estimates}
	\centering
   	 	\includegraphics[width = 0.6\linewidth]{Graphs/s1_catefreq.png}
\end{figure} 

\begin{figure}[h]
\caption{Summary of SHAP Values of Covariate Importance}
	\centering
   	 	\includegraphics[width = 0.6\linewidth]{Graphs/s1_shap.png}
\end{figure} 

\begin{figure}[h]
\caption{Convergence on Sample Size}
	\centering
   	 	\includegraphics[width = \linewidth]{Graphs/s2_nsiz.png}
\end{figure} 




\end{document}



















